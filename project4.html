<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Document Intelligence Pipeline</title>
  <link
    href="https://fonts.googleapis.com/css2?family=Fira+Code:wght@400;600&family=Bebas+Neue&display=swap"
    rel="stylesheet"
  />
  <link rel="stylesheet" href="style.css" />
</head>
<body class="project-detail">
  <header>
    <div class="project-header-shell">
      <div class="project-header-text">
        <a href="index.html" class="back-link"><span aria-hidden="true">‚Üê</span> Back to overview</a>
        <span class="status-chip status-ongoing">Ongoing</span>
        <h1 class="project-title">Document Intelligence Pipeline</h1>
        <p class="project-tagline">
          A modular platform that ingests business documents, classifies them with AI, and validates
          extracted data points against OCR ground truth for trustworthy automation.
        </p>
      </div>
      <div class="project-hero-media">
        <img
          src="images/project4.png"
          alt="Workflow diagram for document processing"
          class="project-hero-image"
        />
      </div>
    </div>
  </header>

  <main class="project-main">
    <section class="project-metrics-grid">
      <div class="project-metric">
        <p class="metric-title">Team Size</p>
        <p class="metric-value">2 specialists</p>
      </div>
      <div class="project-metric">
        <p class="metric-title">Confidence</p>
        <p class="metric-value">9 / 10</p>
      </div>
      <div class="project-metric">
        <p class="metric-title">Budget</p>
        <p class="metric-value">$0 (internal)</p>
      </div>
    </section>

    <section class="project-summary glass-card">
      <h2>Project Overview</h2>
      <p>
        The goal is to turn messy enterprise paperwork into structured, review-ready datasets. We
        fine-tuned a classification model on curated, labeled corpora so it can detect document types
        and extract target fields with high accuracy. Every prediction is cross-checked with the
        original OCR text to keep the loop honest.
      </p>
      <p>
        We split the pipeline into two dedicated branches: a classifier that handles type detection
        plus structured extraction, and a lightweight analysis service for raw text comparisons. This
        modular layout makes it easier to iterate on individual components without breaking the whole
        system.
      </p>
    </section>

    <section class="project-highlights">
      <article class="highlight-card glass-card">
        <h3>Pipeline Highlights</h3>
        <ul>
          <li>OCR ingestion with cleaning routines that prep documents for machine learning.</li>
          <li>Fine-tuned transformer models trained on annotated datasets for each document family.</li>
          <li>Confidence checks that compare extracted values against the raw text stream.</li>
        </ul>
      </article>

      <article class="highlight-card glass-card">
        <h3>Tech Stack</h3>
        <ul class="tag-list">
          <li>Python</li>
          <li>Transformers</li>
          <li>FastAPI</li>
          <li>Tesseract OCR</li>
          <li>PostgreSQL</li>
        </ul>
      </article>

      <article class="highlight-card glass-card">
        <h3>Current Focus</h3>
        <ul>
          <li>Boost recall on edge-case fields through synthetic data augmentation.</li>
          <li>Enhance the reviewer UI with actionable discrepancy insights.</li>
          <li>Ship automated retraining hooks for continuous dataset improvements.</li>
        </ul>
      </article>
    </section>
  </main>

  <footer>
    <p>&copy; 2025 | Created by Jannik Hofstetter</p>
  </footer>
</body>
</html>
